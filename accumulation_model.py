import clickhouse_connect
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier, export_text
from sklearn.model_selection import train_test_split

# --- é…ç½® ---
CLICKHOUSE = dict(host='localhost', port=8123, database='marketdata', username='default', password='12')
SYMBOL = 'BTCUSDT'

def load_data():
    print("ğŸš€ æ­£åœ¨åŠ è½½æ•°æ® (å¯»æ‰¾å¸ç­¹å½¢æ€)...")
    client = clickhouse_connect.get_client(**CLICKHOUSE)
    sql = f"""
    SELECT time, close_price, wall_shift_pct, net_cvd, spoofing_ratio
    FROM marketdata.features_15m
    WHERE symbol = '{SYMBOL}'
    ORDER BY time ASC
    """
    df = client.query_df(sql)
    return df

def feature_engineering_accumulation(df):
    df = df.replace([np.inf, -np.inf], np.nan).dropna()
    
    # --- 1. å®šä¹‰ "æ…¢æ…¢ç§¯ç´¯" çš„æ—¶é—´çª—å£ ---
    # æˆ‘ä»¬çœ‹è¿‡å» 4å°æ—¶ (16æ ¹Kçº¿) åˆ° 12å°æ—¶ (48æ ¹Kçº¿)
    WINDOW = 32 # 8å°æ—¶
    
    # --- 2. èµ„é‡‘ç´¯ç§¯ç‰¹å¾ (CVD Trend) ---
    # è®¡ç®—è¿‡å» 8å°æ—¶çš„ CVD ç´¯ç§¯å€¼
    # å¦‚æœè¿™ä¸ªå€¼å¾ˆå¤§ï¼Œè¯´æ˜ä¸»åŠ›ä¹°äº†å¾ˆå¤šï¼Œä½†å¦‚æœæ˜¯"ç¼“ç¼“"è¿›å…¥ï¼Œæˆ‘ä»¬çœ‹æ–œç‡
    df['cvd_cum'] = df['net_cvd'].rolling(window=WINDOW).sum()
    
    # èµ„é‡‘çš„ä¸€è‡´æ€§ï¼šè¿‡å» 8å°æ—¶é‡Œï¼Œæœ‰å¤šå°‘æ ¹Kçº¿ CVD æ˜¯æ­£çš„ï¼Ÿ
    # æ¯”å¦‚ 32æ ¹Kçº¿é‡Œæœ‰ 25æ ¹æ˜¯æ­£çš„ï¼Œè¯´æ˜æ˜¯æŒç»­ä¹°å…¥ï¼Œè€Œä¸æ˜¯çªå‘ä¹°å…¥
    df['cvd_consistency'] = (df['net_cvd'] > 0).rolling(window=WINDOW).mean()
    
    # --- 3. å¢™çš„å«é«˜ç‰¹å¾ (Wall Build-up) ---
    # ç´¯è®¡çš„å¢™ä½“ç§»åŠ¨ã€‚å¦‚æœé•¿æœŸç´¯ç§¯æ˜¯æ­£çš„ï¼Œè¯´æ˜æ”¯æ’‘ä½åœ¨ä¸æ–­ä¸Šç§»
    df['wall_cum_shift'] = df['wall_shift_pct'].rolling(window=WINDOW).sum()
    
    # --- 4. ä»·æ ¼çš„å‹åˆ¶ç‰¹å¾ (Price Suppression) ---
    # å¸ç­¹çš„ä¸€ä¸ªå…³é”®ç‚¹æ˜¯ï¼šä»·æ ¼ä¸èƒ½æ¶¨ã€‚å¦‚æœä»·æ ¼å·²ç»æ¶¨é£äº†ï¼Œé‚£å°±ä¸æ˜¯å¸ç­¹è€Œæ˜¯æ‹‰å‡äº†ã€‚
    # æˆ‘ä»¬çœ‹è¿‡å» 8å°æ—¶çš„æ¶¨å¹…
    df['price_change_8h'] = df['close_price'].pct_change(periods=WINDOW) * 100
    
    # --- 5. ç›®æ ‡ï¼šéšåçš„å¤§çˆ†å‘ ---
    # å¦‚æœæ»¡è¶³å¸ç­¹ï¼Œæœªæ¥ 24å°æ—¶ (96æ ¹Kçº¿) åº”è¯¥ä¼šæœ‰å¤§æ¶¨
    indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=96)
    df['future_max_return'] = df['close_price'].rolling(window=indexer).max() / df['close_price'] - 1
    
    # æ ‡è®°ï¼šæœªæ¥24å°æ—¶æ¶¨å¹…è¶…è¿‡ 3%ï¼Œä¸”ä¸æ˜¯å‡çªç ´
    df['label'] = 0
    df.loc[df['future_max_return'] > 0.03, 'label'] = 1
    
    df = df.dropna()
    print(f"ğŸ§¹ æ•°æ®é‡æ„å®Œæˆ: {len(df)} æ¡ | ğŸ‹ å·¨é²¸å¸ç­¹æ ·æœ¬: {sum(df['label']==1)}")
    return df

def run_accumulation_scan(df):
    # ç‰¹å¾ï¼šèµ„é‡‘ä¸€è‡´æ€§ã€ç´¯è®¡èµ„é‡‘é‡ã€å¢™çš„ç´¯è®¡ç§»åŠ¨ã€å½“å‰ä»·æ ¼æ¶¨å¹…
    features = ['cvd_consistency', 'cvd_cum', 'wall_cum_shift', 'price_change_8h']
    X = df[features]
    y = df['label'].astype(int)
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)
    
    print("ğŸ§  æ­£åœ¨è®­ç»ƒæ½œä¼è€…æ¨¡å‹ (å¯»æ‰¾çˆ†å‘å‰å¤œ)...")
    clf = DecisionTreeClassifier(
        max_depth=3, # ç®€å•è§„åˆ™
        criterion='entropy', 
        random_state=42, 
        class_weight={0:1, 1:3}, 
        min_samples_leaf=20
    )
    clf.fit(X_train, y_train)
    
    # --- è§„åˆ™è§£æä¸æ¨¡æ‹Ÿ ---
    y_pred = clf.predict(X_test)
    
    # è·å–çœŸå®å›æŠ¥
    real_returns = df.loc[X_test.index, 'future_max_return']
    
    print("\nâš”ï¸ å¼€å¯å¸ç­¹æ‰«æ...")
    trade_count = 0
    wins = 0
    
    for i in range(len(X_test)):
        # å¼ºåˆ¶å¢åŠ äººå·¥é€»è¾‘ï¼šçœŸæ­£çš„å¸ç­¹ï¼Œä»·æ ¼å¿…å®šæ˜¯æ»æ¶¨çš„
        # å¦‚æœè¿‡å»8å°æ—¶å·²ç»æ¶¨äº† > 1%ï¼Œé‚£ä¸ç®—å¸ç­¹ï¼Œé‚£æ˜¯è¿½é«˜
        price_pumped = X_test.iloc[i]['price_change_8h'] > 1.0
        
        if y_pred[i] == 1 and not price_pumped:
            # è¿™æ˜¯ä¸€ä¸ªä¿¡å·ï¼
            ret = real_returns.iloc[i]
            if ret > 0.03: wins += 1
            trade_count += 1
            
    print("\n" + "="*40)
    print(f"ğŸ‹ æ½œä¼è€…æˆ˜æŠ¥")
    print("="*40)
    print(f"ğŸ” å‘ç°ç–‘ä¼¼å¸ç­¹: {trade_count} æ¬¡")
    if trade_count > 0:
        print(f"ğŸ¯ éšå24hæš´æ¶¨ç‡: {wins/trade_count:.2%}")
    else:
        print("â„ï¸ ä¹Ÿå°±æ˜¯æœ€è¿‘ä¸»åŠ›æ²¡æœ‰åœ¨å¸ç­¹ (æˆ–è€…å·²ç»æ‹‰å‡å®Œäº†)")
        
    print("\nğŸ“œ å·¨é²¸å¯†ç  (Tree Rules):")
    print(export_text(clf, feature_names=features))

if __name__ == "__main__":
    df = load_data()
    if not df.empty:
        df = feature_engineering_accumulation(df)
        run_accumulation_scan(df)